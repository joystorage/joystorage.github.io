[{"title":"缓存模拟器-zycache","date":"2017-05-12T07:51:18.523Z","path":"2017/05/12/缓存模拟器-zycache/","text":"为了方便实验，最近自己实现了一套缓存模拟器，以SNIA网站上提供的TRACE为输入，分别实现了FIFO,LRU,LFU,OPT,ARC等经典的缓存算法，整个模拟器通过C++实现，利用面向对象思想。过一段时间我会将源码挂到github上。 运行的大致结果如下： 下面贴出来zy-cache的LRU和OPT算法的实现，其中OPT根据自己的理解分别实现了时间最优算法optt和空间最优算法opts，分别试用于电脑内存空间充足和不足的场景使用。 LRU 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156class lru : public algorithm&#123;private://缓存基本信息 struct list_entry *lru_hot; //lru的hot端 struct list_entry *lru_cold; //lru的cold端 unordered_map&lt;u_int64_t,struct list_entry *&gt; cache_map; //缓存索引public: //缓存基本操作 //初始化 lru(int cache_s, int block_s, int wt) &#123; strcpy(name,&quot;lru&quot;); outfile = NULL; outfile = open_file(&quot;lru.out&quot;); cache_size = cache_s; block_size = block_s; write_type = wt; block_num = cache_size / (512*block_size) ; hit_num = 0; total_num = 0; read_num = 0; ssd_write = 0; lru_cold = lru_hot = NULL; &#125; ~lru() &#123; //销毁lru链表 while(lru_hot != NULL) &#123; struct list_entry *le1 = lru_hot; lru_hot = le1-&gt;next; free(le1); le1 = NULL; &#125; lru_hot = lru_cold = NULL; //销毁map cache_map.clear(); close_file(outfile); outfile = NULL; &#125; void map_operation(u_int64_t key, int io_type,struct trace_inf *ti) &#123; unordered_map&lt;u_int64_t,struct list_entry *&gt;::iterator got = cache_map.find(key); if(got == cache_map.end()) &#123;//未命中 //cout &lt;&lt; cache_map.size() &lt;&lt; endl; if(cache_map.size() == block_num) &#123;//缓存满，需要替换 out_put(ti,lru_cold-&gt;lbn,&quot;Write&quot;);//模拟替换时SSD的写 u_int64_t id_del = lru_cold-&gt;block_id; cache_map.erase(id_del); lru_cold-&gt;next = lru_hot; lru_hot-&gt;pre = lru_cold; lru_hot = lru_cold; lru_cold = lru_cold-&gt;pre; lru_cold-&gt;next = lru_hot-&gt;pre = NULL; lru_hot-&gt;block_id = key; lru_hot-&gt;access_cnt = 1; lru_hot-&gt;pre_access = total_num; cache_map[key] = lru_hot; &#125; else &#123; struct list_entry * le = (struct list_entry *)malloc(sizeof(list_entry)); le-&gt;lbn = cache_map.size(); if(lru_hot == NULL) &#123; le-&gt;next = le-&gt;pre = NULL; le-&gt;block_id = key; le-&gt;access_cnt = 1; le-&gt;pre_access = total_num; lru_hot = lru_cold = le; cache_map[key] = le; out_put(ti,le-&gt;lbn,&quot;Write&quot;);//模拟替换时SSD的写 &#125; else &#123; le-&gt;pre = NULL; le-&gt;block_id = key; le-&gt;access_cnt = 1; le-&gt;pre_access = total_num; le-&gt;next = lru_hot; lru_hot-&gt;pre = le; lru_hot = le; cache_map[key] = le; out_put(ti,le-&gt;lbn,&quot;Write&quot;);//模拟替换时SSD的写 &#125; le = NULL; &#125; &#125; else &#123;//命中 struct list_entry * le = got-&gt;second; if(lru_hot != le) &#123; le-&gt;pre-&gt;next = le-&gt;next; if(le-&gt;next != NULL)&#123; le-&gt;next-&gt;pre = le-&gt;pre; &#125;else&#123; lru_cold = le-&gt;pre; lru_cold-&gt;next = NULL; &#125; le-&gt;next = lru_hot; lru_hot-&gt;pre = le; le-&gt;pre = NULL; lru_hot = le; &#125; le-&gt;access_cnt++; le-&gt;pre_access = total_num; hit_num++; if(io_type == 1)&#123; //写与读不同的地方 out_put(ti,le-&gt;lbn,&quot;Write&quot;);//模拟替换时SSD的写 &#125; else &#123; out_put(ti,le-&gt;lbn,&quot;Read&quot;);//模拟替换时SSD的写 &#125; le = NULL; &#125; //lru链表测试#if DEBUG struct list_entry *le1 = lru_hot; while(le1 != NULL)&#123; cout &lt;&lt; le1-&gt;block_id &lt;&lt; &quot;\\t&quot;; le1 = le1-&gt;next; &#125; cout &lt;&lt; endl;#endif &#125;&#125;; opt 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399#include &lt;list&gt;struct next_acc&#123; u_int64_t num; struct next_acc *next;&#125;;struct map_entry&#123; int acc_num; struct next_acc *head; struct next_acc *tail;&#125;;class optt : public algorithm&#123; //opt时间最优算法 //且处理时间为log(n)级别 //得到opt绝对最优解，内存空间充足情况下使用private://缓存基本信息 unordered_map&lt;u_int64_t,struct list_entry *&gt; cache_map; //缓存索引 struct list_entry cache_entry[block_num_conf]; unordered_map&lt;u_int64_t,struct map_entry *&gt; io_map; //预处理map u_int64_t pre_cnt; u_int64_t total_rec;public: //缓存基本操作 //初始化 optt(int cache_s, int block_s, int wt) &#123; outfile = NULL; outfile = open_file(&quot;opt.out&quot;); strcpy(name,&quot;opt&quot;); cache_size = cache_s; block_size = block_s; write_type = wt; block_num = cache_size / (512*block_size) ; hit_num = 0; total_num = 0; read_num = 0; ssd_write = 0; pre_cnt = 0; total_rec = 1.8446744*1e19; //memset(cache_entry,0xff,block_num_conf); &#125; ~optt() &#123; //销毁map io_map.clear(); cache_map.clear(); close_file(outfile); outfile = NULL; &#125; void map_operation(u_int64_t key, int io_type,struct trace_inf *ti) &#123; unordered_map&lt;u_int64_t,struct list_entry *&gt;::iterator got = cache_map.find(key); if(got == cache_map.end()) &#123;//未命中 int map_size = cache_map.size(); //cout &lt;&lt; cache_map.size() &lt;&lt; endl; if(map_size == block_num) &#123;//缓存满，需要替换 int victim = find_victim(); u_int64_t id_del = cache_entry[victim].block_id; cache_map.erase(id_del); cache_entry[victim].block_id = key; cache_entry[victim].access_cnt = 1; cache_entry[victim].pre_access = total_num; cache_entry[victim].next_access = find_next(key); cache_map[key] = &amp;cache_entry[victim]; out_put(ti,victim,&quot;Write&quot;);//模拟替换时SSD的写 &#125; else &#123; cache_entry[map_size].block_id = key; cache_entry[map_size].access_cnt = 1; cache_entry[map_size].pre_access = total_num; cache_entry[map_size].next_access = find_next(key); cache_entry[map_size].lbn = map_size; cache_map[key] = &amp;cache_entry[map_size]; out_put(ti,map_size,&quot;Write&quot;);//模拟替换时SSD的写 &#125; &#125; else &#123;//命中 struct list_entry * le = got-&gt;second; le-&gt;access_cnt++; le-&gt;pre_access = total_num; le-&gt;next_access = find_next(key); hit_num++; if(io_type == 1)&#123; //写与读不同的地方 out_put(ti,le-&gt;lbn,&quot;Write&quot;);//模拟替换时SSD的写 &#125; else &#123; out_put(ti,le-&gt;lbn,&quot;Read&quot;);//模拟替换时SSD的写 &#125; le = NULL; &#125; //lru链表测试#if DEBUG int cs = cache_map.size(); for(int i=0 ; i &lt; cs ; i++) &#123; cout &lt;&lt; cache_entry[i].block_id &lt;&lt; &quot;\\t&quot;; &#125; cout &lt;&lt; endl;#endif &#125; int find_victim() &#123; int cs = cache_map.size(); int result = 0; int max_next = cache_entry[0].next_access; //cout &lt;&lt; cs &lt;&lt; &quot;\\t&quot;; for(int i=0 ; i &lt; cs ; i++) &#123; //cout &lt;&lt; cache_entry[i].block_id &lt;&lt; &quot;\\t&quot;; if(cache_entry[i].next_access &gt; max_next) &#123; max_next = cache_entry[i].next_access; result = i; &#125; &#125; return result; &#125; u_int64_t find_next(u_int64_t block_id) &#123; unordered_map&lt;u_int64_t,struct map_entry*&gt;::iterator it = io_map.find(block_id); struct next_acc *nt = NULL; struct map_entry *me = NULL; if(it != io_map.end()) &#123; me = it-&gt;second; if(me-&gt;head == NULL) &#123; return total_rec + 1; &#125; else&#123; nt = me-&gt;head; me-&gt;head = nt-&gt;next; delete nt; if(me-&gt;head != NULL) &#123; return me-&gt;head-&gt;num; &#125; else &#123; return total_rec + 1; &#125; &#125; &#125; else &#123; cout &lt;&lt; &quot;Severe Error!!!&quot; &lt;&lt; endl; exit(0); &#125; &#125; //初始化io_list void init_io_list(struct trace_inf *ti) &#123; struct bio *head = div_block(ti); while(head != NULL) &#123; pre_cnt++; unordered_map&lt;u_int64_t,struct map_entry*&gt;::iterator it = io_map.find(head-&gt;block_id); struct next_acc *nt = NULL; struct map_entry *me = NULL; if(it == io_map.end()) &#123; me = (struct map_entry*)malloc(sizeof(struct map_entry)); nt = (struct next_acc *)malloc(sizeof(struct next_acc)); nt-&gt;num = pre_cnt; nt-&gt;next = NULL; me-&gt;head = me-&gt;tail = nt; me-&gt;acc_num = 1; io_map[head-&gt;block_id] = me; &#125;else&#123; nt = (struct next_acc *)malloc(sizeof(struct next_acc)); nt-&gt;num = pre_cnt; nt-&gt;next = NULL; me = it-&gt;second; me-&gt;tail-&gt;next = nt; me-&gt;tail = nt; me-&gt;acc_num++; &#125; head = head-&gt;next; &#125; &#125; void show_io_list()&#123; struct next_acc *nt = NULL; struct map_entry *me = NULL; for ( unordered_map&lt;u_int64_t,struct map_entry*&gt;::iterator it=io_map.begin(); it != io_map.end(); ++it) &#123; me = it-&gt;second; nt = me-&gt;head; cout &lt;&lt; it-&gt;first &lt;&lt; &quot;\\t&quot; &lt;&lt; me-&gt;acc_num &lt;&lt; &quot;\\t&quot;; while(nt != NULL) &#123; cout &lt;&lt; nt-&gt;num &lt;&lt; &quot;\\t&quot;; nt = nt-&gt;next; &#125; cout &lt;&lt; endl; &#125; &#125;&#125;;class opts : public algorithm&#123; //opt空间最优算法，可以通过OPT_DEGREE调整算法级别，得到的知识opt的一个次优解 //OPT_DEGREE为1-10的整数，在conf.h中进行设置，数越大越接近理论最优，但是运行时间也越长 //内存空间有限的情况下使用 //时间复杂度为n*nprivate://缓存基本信息 unordered_map&lt;u_int64_t,struct list_entry *&gt; cache_map; //缓存索引 struct list_entry cache_entry[block_num_conf]; list&lt;u_int64_t&gt; io_list;public: //缓存基本操作 //初始化 opts(int cache_s, int block_s, int wt) &#123; strcpy(name,&quot;opt&quot;); cache_size = cache_s; block_size = block_s; write_type = wt; block_num = cache_size / (512*block_size) ; hit_num = 0; total_num = 0; read_num = 0; ssd_write = 0; //memset(cache_entry,0xff,block_num_conf); &#125; ~opts() &#123; //销毁map cache_map.clear(); &#125; void map_operation(u_int64_t key, int io_type,struct trace_inf *ti) &#123; unordered_map&lt;u_int64_t,struct list_entry *&gt;::iterator got = cache_map.find(key); if(got == cache_map.end()) &#123;//未命中 int map_size = cache_map.size(); //cout &lt;&lt; cache_map.size() &lt;&lt; endl; if(map_size == block_num) &#123;//缓存满，需要替换 int victim = find_victim(); u_int64_t id_del = cache_entry[victim].block_id; cache_map.erase(id_del); cache_entry[victim].block_id = key; cache_entry[victim].access_cnt = 1; cache_entry[victim].pre_access = total_num; cache_entry[victim].next_access = find_next(key); cache_map[key] = &amp;cache_entry[victim]; out_put(ti,victim,&quot;Write&quot;);//模拟替换时SSD的写 &#125; else &#123; cache_entry[map_size].block_id = key; cache_entry[map_size].access_cnt = 1; cache_entry[map_size].pre_access = total_num; cache_entry[map_size].next_access = find_next(key); cache_entry[map_size].lbn = map_size; cache_map[key] = &amp;cache_entry[map_size]; out_put(ti,map_size,&quot;Write&quot;);//模拟替换时SSD的写 &#125; &#125; else &#123;//命中 struct list_entry * le = got-&gt;second; le-&gt;access_cnt++; le-&gt;pre_access = total_num; le-&gt;next_access = find_next(key); hit_num++; if(io_type == 1)&#123; //写与读不同的地方 out_put(ti,le-&gt;lbn,&quot;Write&quot;);//模拟替换时SSD的写 &#125; else &#123; out_put(ti,le-&gt;lbn,&quot;Read&quot;);//模拟替换时SSD的写 &#125; le = NULL; &#125; //lru链表测试#if DEBUG int cs = cache_map.size(); for(int i=0 ; i &lt; cs ; i++) &#123; cout &lt;&lt; cache_entry[i].block_id &lt;&lt; &quot;\\t&quot;; &#125; cout &lt;&lt; endl;#endif &#125; int find_victim() &#123; int cs = cache_map.size(); int result = 0; int max_next = cache_entry[0].next_access; //cout &lt;&lt; cs &lt;&lt; &quot;\\t&quot;; for(int i=0 ; i &lt; cs ; i++) &#123; //cout &lt;&lt; cache_entry[i].block_id &lt;&lt; &quot;\\t&quot;; if(cache_entry[i].next_access &gt; max_next) &#123; max_next = cache_entry[i].next_access; result = i; &#125; &#125; return result; &#125; u_int64_t find_next(u_int64_t block_id) &#123; u_int64_t result = total_num; int cnt = 0; for (list&lt;u_int64_t&gt;::iterator it=io_list.begin(); it != io_list.end(); ++it) &#123; cnt++; if(*it == block_id) &#123; break; &#125; if(cnt &gt; OPT_DEGREE * block_num_conf)&#123; cnt = io_list.size()*2; break; &#125; &#125; return (result + cnt - 1); &#125; //初始化io_list void init_io_list(struct trace_inf *ti) &#123; struct bio *head = div_block(ti); while(head != NULL) &#123; io_list.push_back(head-&gt;block_id); head = head-&gt;next; &#125; &#125; void show_io_list()&#123; for (list&lt;u_int64_t&gt;::iterator it=io_list.begin(); it != io_list.end(); ++it) &#123; cout &lt;&lt; *it &lt;&lt; &quot;\\t&quot;; &#125; cout &lt;&lt; endl; &#125;&#125;;","tags":[{"name":"存储","slug":"存储","permalink":"http://yoursite.com/tags/存储/"},{"name":"zycache","slug":"zycache","permalink":"http://yoursite.com/tags/zycache/"},{"name":"缓存","slug":"缓存","permalink":"http://yoursite.com/tags/缓存/"}]},{"title":"般若波罗蜜多心经","date":"2017-04-28T05:37:21.005Z","path":"2017/04/28/般若波罗蜜多心经/","text":"原文123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475bō rě bō luó mì duō xīn jīng般若波罗蜜多心经guān zì zài pú sà , xíng shēn bō rě bō luó mì duō shí，zhào jiàn wǔ yùn jiē kōng, dù yī qiē kǔ è。观自在菩萨，行深般若波罗蜜多时，照见五蕴皆空，度一切苦厄。shè lì zǐ, sè bù yì kōng ，kōng bù yì sè , sè jí shì kōng , kōng jí shì sè。舍利子，色不异空，空不异色，色即是空，空即是色。shòu xiǎng xíng shí，yì fù rú shì。受想行识，亦复如是。shè lì zǐ, shì zhū fǎ kōng xiāng,舍利子，是诸法空相，bù shēng bù miè, bù gòu bù jìng, bù zēng bù jiǎn ,不生不灭，不垢不净，不增不减，shì gù kōng zhōng wú sè, wú shòu xiǎng xíng shí,是故空中无色，无受想行识，wú yǎn ěr bí shé shēn yì, wú sè shēng xiāng wèi chù fǎ, wú yǎn jiè,无眼耳鼻舌身意，无色声香味触法，无眼界，nǎi zhì wú yì shí jiè, wú wú míng , yì wú wú míng jìn,乃至无意识界，无无明，亦无无明尽，nǎi zhì wú lǎo sǐ, yì wú lǎo sǐ jìn。乃至无老死，亦无老死尽。wú kǔ jí miè dào, wú zhì yì wú dé, yǐ wú suǒ dé gù。无苦集灭道，无智亦无得，以无所得故。pú tí sà duǒ yī bō rě bō luó mì duō gù xīn wú guà ài。菩提萨埵，依般若波罗蜜多故，心无挂碍。wú guà ài gù, wú yǒu kǒng bù, yuǎn lí diān dǎo mèng xiǎng, jiū jìng niè pán。无挂碍故，无有恐怖，远离颠倒梦想，究竟涅槃。sān shì zhū fó, yī bō rě bō luó mì duō gù, dé ā nuò duō luó sān miǎo sān pú tí。三世诸佛，依般若波罗蜜多故，得阿耨多罗三藐三菩提。gù zhī bō rě bō luó mì duō, shì dà shén zhòu, shì dà míng zhòu,故知般若波罗蜜多，是大神咒，是大明咒，shì wú shàng zhòu, shì wú děng děng zhòu。néng chú yī qiē kǔ, zhēn shí bù xū。是无上咒，是无等等咒。能除一切苦，真实不虚。gù shuō bō rě bō luó mì duō zhòu。故说般若波罗蜜多咒。jí shuō zhòu yuē：即说咒曰：jiē dì jiē dì, bō luó jiē dì, bō luó sēng jiē dì, pú tí sà pó hē。揭谛揭谛，波罗揭谛，波罗僧揭谛，菩提萨婆诃。 经名整段话的概略意思是“透过心量广大的通达智慧，而超脱世俗困苦的根本途径”。 “摩诃”：无边无际的大、心量广大[1]。比喻宇宙万物大自然之间的规律与特质，约略相当于中国传统文化指称的道与广义的命。 “般若”为梵语音译，指通达妙智慧; “波罗”为梵语音译，指到彼岸(不生不灭、不垢不净)，有解脱挂碍的意思; “蜜多”为梵语音译，意为无极。可联想比如蜜蜂采花酿蜜，能融合众多不同来源成分而归纳为一。 “心”：根本、核心、精髓。一方面表示内容所探讨的主体重心，另一方面也表示全篇内容的重要性。 “经”：字义是线、路、径，引申为经典。代表前人走过的路途、独特而深入的经历或见解，借口述语言或文字记载来传承后世，以供人们做为参考指引。 经文心经经文以“观自在菩萨”开头，以“菩提萨婆诃”结尾(萨婆诃本为祝颂语，亦有观自在的意思，与经文开头相呼应)。 “舍利子(舍利弗)”是心经全文关键字词之一。 起源释迦牟尼佛初转法轮先说四圣谛，即苦集灭道。灭谛中提及涅槃，为了阐释涅槃的内涵及意义，佛陀更深入说明空性之理。第二转无相法轮，借由对空性的认知，证明烦恼是可以断除的，从色法到一切遍智空，一切法皆无自性。有些论师不了解甚深空性，佛陀便对无自性再做解释，第三转善分别法轮的《解深密经》、《如来藏经》、慈氏菩萨的《相续本母经》，详细说明心的体性是惟明惟知，具有原始自然之光明。 《般若经》及诸部般若，为佛陀在二转无相法轮时所宣说，乃大乘佛法中之深法。在藏传的经论中经常提到：“佛说八万四千法门中，般若法门最为殊胜。” 《般若经》的内涵以空性为主，透过对空性的了解能断除烦恼障而得到小乘的涅槃，即声闻及独觉的菩提果位;也能够透过对空性的认识，再加上福德资粮的圆满，能彻底断除所知障而获得大乘的涅槃，即无上的菩提果位。因为解了空性贯穿三乘，故解空被称为三乘之母，诠释它的般若经亦称为母般若。《般若波罗密多心经》即是《大般若经》的心髓，全部般若的精义皆设于此经[2]，故名为《心经》。 佛说《心经》的缘起，是在灵鹫山中部，为诸菩萨声闻弟子所围绕，当时观自在菩萨正在观修般若波罗密多、专注思惟观修而照见五蕴皆自性空。心经主要内涵是舍利子与观自在菩萨有关空性的问答。佛出定后，认可菩萨所说，欢喜赞叹。 心经内涵可分两种，显义与隐义。显义为观空正见，为龙树菩萨的《中论》所阐释。隐义则为现观道次第，间接显示空性所依的有法，为弥勒菩萨所造的《现观庄严论》所诠释。 有学者认为《心经》经文结构之来源，大部分出于《大般若经》第二会观照品第三之二，即《大品般若》习应品第三)。“般若波罗密多是大神咒……”一段，出于《大般若经》第二会功德品第三十二，即《大品般若》劝持品第三十四。咒文则出于《佛说陀罗尼集经》第三卷，般若大心陀罗尼第十六。故《心经》是出自《般若经》的精髓，附加密咒真言，同时奉请观自在菩萨为其说法主，才完成现今《心经》组织的型态[3]。 《大般若经》中所开示之般若法门是专为已发菩提心之众菩萨们所宣说的。其最重要的观念在于以空性智慧觉悟诸法实相(即一切外在事物的名相，皆是自心的虚妄分别而已)，既不体证、进入涅槃而自愿生生世世轮回生死救度众生，其行为看似有违一般所认知的脱离轮回观念，而实际上这才是《大般若经》开悟菩萨的主旨所在。因为以慈悲喜舍之心平等救护一切众生才是真菩萨行，而自己逃离生死轮回却弃众生于不顾则有违菩萨自度度他之初衷誓愿。 在《大般若经》中数度出现 “菩萨摩诃萨普为利乐诸有情故，求趣无上正等菩提”与 “观诸法皆空，不舍一切有情”字句。此即表示若离开对众生的慈悲济度，则一切修行的意义则大打折扣，不能最终成就无上菩提正果。 白话解释12345678910111213141516171819202122232425262728293031323334353637383940414243444546观自在菩萨（般若智慧已经达到自在境界的菩萨）行深般若波罗蜜多时（当他修行般若智慧达到波罗蜜多觉悟境界的时候）照见五蕴皆空（洞见色、受、想、行、识五蕴乃是人类虚空的妄想）度一切苦厄（所以菩萨要为众生解脱一切执着于生死烦恼的苦厄）舍利子（智慧第一的舍利子啊）色不异空（你所看见的物质世界其实是你的精神世界）空不异色（你的精神世界也就是你以为的物质世界）色即是空（物质世界就是精神世界）空即是色（精神世界就是物质世界）受想行识亦复如是（人类所谓的感受、思想、行为和认识也是如此）舍利子（智慧第一的舍利子啊）是诸法空相（其实一切法都不是法，只是人类虚空的精神幻觉）不生不灭（真实的世界不会产生，也不会灭亡）不垢不净（不会被尘埃沾污，也不需要去洁净）不增不减（任何东西都不会增加，也不会减少）是故空中无色（在真实世界里并没有物质这一概念）无受想行识（自然也就不存在人类对物质世界的感受、思想、行为和认识）无眼耳鼻舌身意（眼、耳、鼻、舌、身、意这六种感官对于真实世界没有任何意义）无色声香味触法（自然也就不存在所谓的颜色、声音、香气、味道、感觉和概念）无眼界乃至无意识界（你眼睛所看到的一切都是假象，你的意识也全部都是错觉）无无明亦无无明尽（没有前世愚昧的事情，也没有后世报应的所谓十二因缘）乃至无老死（就连生老病死也是胡说）亦无老死尽（更没有生死轮回的道理）无苦集灭道（没有生死烦恼，没有贪婪和恐惧，也没有所谓的真理）无智亦无得（既没有智慧，也得不到任何知识）以无所得故（这才是超越了人类精神的惟一真实的世界）菩提萨埵（大慈大悲普度众生的观自在菩萨）依般若波罗蜜多故（依靠般若智慧抵达了波罗蜜多觉悟的彼岸）心无罣碍，无罣碍故（心中没有任何牵挂和妨碍，正是因为没有受到人类精神影响的缘故）无有恐怖，远离颠倒梦想（没有任何恐怖，远离那些违背自然的思想）究竟涅盘（所以菩萨观得自在，消除了一切烦恼）三世诸佛（过去、现在和将来三世佛以及一切佛）依般若波罗蜜多故（都是依靠般若智慧达到波罗蜜多觉悟的境界）得阿耨多罗三藐三菩提（得到阿耨多罗无上三藐正等三菩提正觉成佛的境界）故知般若波罗蜜多是大神咒（所以般若智慧波罗蜜多觉悟是不可思议的咒语）是大明咒（是普照一切的咒语）是无上咒（是最最伟大的咒语）是无等等咒（是超度一切的咒语）能除一切苦（能够解除人生的一切生死烦恼和苦厄）真实不虚（佛无妄语，自然真实）故说般若波罗蜜多咒（所以这是众生修行般若智慧抵达波罗蜜多觉悟的密咒）即说咒曰（咒语曰）揭谛揭谛（去吧去吧）波罗揭谛（走过所有的道路）波罗僧揭谛（一起去向人生的彼岸）菩提萨婆诃（欢呼觉悟吧） 转载自：心经全文 般若波罗蜜多心经(全文注音、拼音)","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"},{"name":"转载","slug":"转载","permalink":"http://yoursite.com/tags/转载/"}]},{"title":"自我管理规范","date":"2017-04-28T05:37:20.971Z","path":"2017/04/28/自我管理规范/","text":"夏 （清明-国庆） 时间 备注 7:00 起床 8:00-10:00 英语 10:00-11:30 上午（先列计划） 12:20-13:20 午休 13:30-17:00 下午 18:00-22:00 晚间 11:30 睡觉 冬 时间 备注 7:30 起床 8:30-10:30 英语 10:30-11:30 上午 （先列计划） 12:20-12:50 午休 13:00-17:00 下午 18:00-22:00 晚间 11:30 睡觉 备注 注意 备注 实验室不娱乐，寝室不工作 ☆ 每天写计划，每月自我总结 ☆ 每两周发周报 ☆ 每月保持与老板沟通一次 ☆ 每隔一天要锻炼半小时 ☆ 每周工作54h，单休(周六或者周日，可自行调整) ☆ 周二周四早上可以十点之前到 满勤月月底双休 Efficiency得分为实际工作时间比上应工作时间,Tasks得分为每日完成的计划数比上总计划数 每年培养一门兴趣爱好 ☆","tags":[{"name":"自我管理","slug":"自我管理","permalink":"http://yoursite.com/tags/自我管理/"}]},{"title":"17年4月总结","date":"2017-04-28T05:37:20.969Z","path":"2017/04/28/17年4月总结/","text":"本月上完了博士生所有的课程，设置了一套自己的自我管理规范，督促自己每天按时到实验室搬砖！下面是本月的统计结果及总结！ 统计图表 得分满分70分，得分47.2 ，换算成百分制为67分 几点注意 本周的survey没有做完，周报需要延迟发送，五一假期需要加班完成！ 4月29日与30号上午设置加班，survey与周报必须完成，不得延误！ 临近放假的两三天，效率较低，心不够静！ 英语得抓紧！ 写在最后第一点就是临近假期效率低的毛病很突出，直接导致工作日的工作无法正常完成而拖到假期，本月就是例子！！！今后一定要注意，越到最后越要沉住气，把手头工作做完再想着去休息。 第二点就是不要东拉西扯，手头有事就先集中精力做手头的事，以做完手头的事为小目标，想方设法实现这一小目标，这样有助于提高效率，改掉拖延症！！","tags":[{"name":"月总结","slug":"月总结","permalink":"http://yoursite.com/tags/月总结/"},{"name":"自我管理","slug":"自我管理","permalink":"http://yoursite.com/tags/自我管理/"}]},{"title":"一叶孤舟，自强不息","date":"2017-04-20T13:26:34.271Z","path":"2017/04/20/一叶孤舟，自强不息/","text":"这一年，感觉是二十多年来成长最多的一年，并不是提升了多少专业技能，看了多少论文，而是看透了很多事，认识到了自身的诸多不足，这一点得感谢老板的谆谆教诲。 研一的生活主要是上课，老板并没有在科研上过多的push，也没有见过几次面。但仅有的几次交流却让我认识到了自身的很多缺点，而这些是我二十多年都没有看到的。这也是为什么佩服老板了，看的透彻，总是一语道破，而且没有一句大话、空话！ 总结有以下几点： 责任心不够强，不够自立！ 做事不够高效专注，停留表面，较为浮躁！ 交流不能抓住重点！ 我认识到这些缺点对我来说是致命的，足以掩盖我所有的优点！ 我仔细分析了为什么会这样，找到了问题的根结所在，并且做了如下的努力： 经济独立，学会独处家中老幺，从小在家娇生惯养，让我过分依赖父母，这种依赖不光是经济上的，更是精神上的，精神上的不自立是最可怕的，这也是为什么会责任心不强，遇事不先考虑自己处理，而是首先寻求他人援助，因此也就显得没有主见，永远像个奶油小生！ 意识到这一点，我做了两件事！ 经济独立 从上学期开始，就不再向家中要一分钱了，自己养活自己，不管钱多钱少，艰苦与否，自己学会理财，不向家中寻求帮助！ 独处 这种独处不是自闭，不社交，相反，社交生活不能少，只是遇事少找人倾述，不要对任何人产生依赖，自己学会分析考虑问题，少发牢骚，多干实事！ 坚持，自律读研以后我越发感觉到自己的浮躁，不能静下心来做一件事，总是东一榔头，西一棒槌！这应该是小学就有的恶习，甚至高考还在上面栽了跟头。高考的痛楚让我在本科学习一直目标明确，最后也成功保研。但是近来，特别是大四保研以后，浮躁的恶习又有了反弹。年后，发现这个苗头后，防微杜渐，便做了三件事！ 坚持锻炼 每天晚上只要天气好，就坚持去操场跑五圈，跑的不多，贵在坚持！ 坚持背单词 其实这是很多人都坚持不下来的事，但是至今已经坚持了两个多月，且英语水平提高显著！ 自律，自我管理，坚持早起 实验室没有打卡，因此很多人都较为懒散。年后，我开始了自我管理，制定时间表，自觉到实验室科研，早睡早起。现在发现自己不仅精神十足，效率高，并且心情也变好了。 多做presentation，同时培养多门兴趣爱好 Presentation 研讨课上主动做presentation，读完论文，或者学了某项技术后花大量时间总结，关键是总结时要理清思路，培养自己的逻辑思维能力；与此同时每两周给老板发一次周报，注意周报的表述方式，尽量让老板想看，且看一遍就能懂！ 培养兴趣，陶冶情操 分析自己抓不住重点的原因，应该和情商低有关，表达时不知道别人最想知道什么，因此也不很好的向别人转述自己的想法。为了提高情商，陶冶情操，年后我开始了在科研之余练习书法，学习唱歌，看小说，下一步准备学吉他和非洲鼓！ 改掉恶习，非一朝一夕之功，有很多地方仍然做的不太好，但是已有一定成效，滴水穿石，贵在坚持！ 最后，这是老板之前对我说的一番话：“人生就是这样，没有如果，只有结果！人生是残酷的，没人会同情弱者，要努力让自己变强，增加自己的魅力，遇事莫等人，自强不息！” 共勉之！","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]},{"title":"安和桥","date":"2017-04-20T06:17:37.131Z","path":"2017/04/20/安和桥/","text":"不得不说，一段非洲鼓奏乐令人印象深刻 敲鼓节奏 歌词 12345678910111213141516171819202122232425262728293031323334353637让我再看你一遍从南到北像是被五环路蒙住的双眼请你再讲一遍关于那天抱着盒子的姑娘擦汗的男人我知道 那些夏天就像青春一样回不来代替梦想的也只能是勉为其难我知道 吹过的牛逼也会随青春一笑了之让我困在城市里纪念你让我再尝一口秋天的酒一直往南方开不会太久让我再听一遍最美的那一句你回家了我在等你呢（music）我知道那些夏天就像青春一样回不来代替梦想的也只能是勉为其难我知道吹过的牛逼也会随青春一笑了之让我困在城市里 纪念你我知道那些夏天就像你一样回不来我已不会再对谁满怀期待我知道这个世界每天都有太多遗憾所以 你好 再见","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]},{"title":"VSCode配置","date":"2017-04-19T03:34:34.450Z","path":"2017/04/19/VSCode配置/","text":"工欲善其事必先利其器，学长都推荐source insight来看代码，用了一段时间，感觉还是不太方便，于是开始转战VS Code了！VS Code确实是一个不错的编辑器，而且支持Linux/Mac Os/Windows系统。 为什么用它看代码会比较方便呢？比如我要看下面这个变量buswait的定义(图1)，只需要按住ctl点击该变量即可转到定义(图2)，是不是跟eclipse的功能有点像呢！！！对于我这种JAVA转战C的码农简直就是天降福利啊，而且还支持分屏显示(图3)！！！ 图1.图2. 图3. 当然VS code还可以用来编译调试C/C++代码，下面说一下具体配置过流程 流程： 下载安装vscode 安装cpptools插件 安装编译、调试环境 修改vscode调试配置文件 下载安装vscodehttps://code.visualstudio.com/Download 安装VSCode的C++插件Ctrl+P，再输入ext install cpptools 进行安装。 安装TDM-GCC(编译调试环境)VSCode默认不带编译和调试环境的，需要自行安装编译器等。 我选用的是TDM-GCC编译套件，方便易用。（Codeblocks、Dev-Cpp等默认带的都是这款）。 下载地址：http://tdm-gcc.tdragon.net/download 根据自己的情况下载安装即可，会自动添加路径到环境变量PATH。 ==重启电脑，让环境变量生效！！！== 配置VSCode 新建test.cpp 1234567891011#include &lt;iostream&gt;using namespace std;int main(int argc, char** argv)&#123; cout &lt;&lt; &quot;Hello World! &quot; &lt;&lt; endl; system(&quot;pause&quot;); return 0;&#125; 按F5，打开launch.json文件，编辑并保存 123456789101112131415161718192021&#123; &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;C++ Launch&quot;, // 配置名称，将会在启动配置的下拉菜单中显示 &quot;type&quot;: &quot;cppdbg&quot;, // 配置类型，这里只能为cppdbg &quot;request&quot;: &quot;launch&quot;, // 请求配置类型，可以为launch（启动）或attach（附加） &quot;launchOptionType&quot;: &quot;Local&quot;, // 调试器启动类型，这里只能为Local &quot;targetArchitecture&quot;: &quot;x86&quot;, // 生成目标架构，一般为x86或x64，可以为x86, arm, arm64, mips, x64, amd64, x86_64 &quot;program&quot;: &quot;$&#123;fileDirname&#125;/$&#123;fileBasenameNoExtension&#125;.exe&quot;, // 将要进行调试的程序的路径 &quot;miDebuggerPath&quot;: &quot;gdb.exe&quot;, // miDebugger的路径，注意这里要与MinGw的路径对应。64位系统用gdb64.exe &quot;args&quot;: [ &quot;&quot; ], // 程序调试时传递给程序的命令行参数，一般设为空即可 &quot;stopAtEntry&quot;: false, // 设为true时程序将暂停在程序入口处，我一般设置为true &quot;cwd&quot;: &quot;$&#123;workspaceRoot&#125;&quot;, // 调试程序时的工作目录，一般为$&#123;workspaceRoot&#125;即代码所在目录 &quot;externalConsole&quot;: true, // 调试时是否显示控制台窗口，一般设置为true显示控制台 &quot;preLaunchTask&quot;: &quot;g++&quot; // 调试会话开始前执行的任务，一般为编译程序，c++为g++, c为gcc &#125; ]&#125; 按F1键，出来输入框后，输入task，选择“配置任务运行程序”，再随便选一项，编辑并保存tasks.json： 12345678910111213141516171819202122232425&#123; &quot;version&quot;: &quot;0.1.0&quot;, &quot;command&quot;: &quot;g++&quot;, &quot;args&quot;: [ &quot;-g&quot;, &quot;$&#123;file&#125;&quot;, &quot;-o&quot;, &quot;$&#123;fileDirname&#125;/$&#123;fileBasenameNoExtension&#125;.exe&quot; ], // 编译命令参数 &quot;problemMatcher&quot;: &#123; &quot;owner&quot;: &quot;cpp&quot;, &quot;fileLocation&quot;: [ &quot;relative&quot;, &quot;$&#123;workspaceRoot&#125;&quot; ], &quot;pattern&quot;: &#123; &quot;regexp&quot;: &quot;^(.*):(\\\\d+):(\\\\d+):\\\\s+(warning|error):\\\\s+(.*)$&quot;, &quot;file&quot;: 1, &quot;line&quot;: 2, &quot;column&quot;: 3, &quot;severity&quot;: 4, &quot;message&quot;: 5 &#125; &#125;&#125; 在.vscode目录下新建文件c_cpp_properties.json，编辑并保存： 12345678910111213141516171819202122&#123; &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;Win32&quot;, &quot;includePath&quot;: [ &quot;D:/Program Files/TDM-GCC-64/include&quot;, &quot;D:/Program Files/TDM-GCC-64/x86_64-w64-mingw32/include&quot;, &quot;D:/Program Files/TDM-GCC-64/lib/gcc/x86_64-w64-mingw32/5.1.0/include&quot;, &quot;D:/Program Files/TDM-GCC-64/lib/gcc/x86_64-w64-mingw32/5.1.0/include/c++&quot; ], &quot;browse&quot;: &#123; &quot;limitSymbolsToIncludedHeaders&quot;: true, &quot;databaseFilename&quot;: &quot;&quot; &#125; &#125; ], &quot;clang_format&quot;: &#123; &quot;style&quot;: &quot;file&quot;, &quot;fallback-style&quot;: &quot;LLVM&quot;, &quot;sort-includes&quot;: false &#125;&#125; 按F5进行调试，结果如下 参见Dreamlike博客","tags":[{"name":"VSCode","slug":"VSCode","permalink":"http://yoursite.com/tags/VSCode/"},{"name":"c++","slug":"c","permalink":"http://yoursite.com/tags/c/"}]},{"title":"存储相关-2-RAID、虚拟磁盘、卷和文件系统","date":"2017-04-03T11:19:36.349Z","path":"2017/04/03/存储相关-2-RAID、虚拟磁盘、卷和文件系统/","text":"七种RAIDRAID以4个扇区组成的块作为基本单位，不同磁盘的相同偏移处的块组成Stripe，也就是条带.对于RAID 0 磁盘组，如果有大块数据写入时，则数据在很大几率上可以以条带为单位写入，并行写入能大大提高写入速度. 简介 RAID 0没有冗余，通过并行写入提高性能. RAID 1 RAID 0 数据不安全，一块盘坏掉，整个阵列就坏了.因此RAID 1 拿另一磁盘做备份，即一次性写两份. 读性能和顺序写性能提高N倍，但随机写由于公用同一块备份盘，因此性能没有提升. RAID 2 采用Hamming Code ECC进行校验.汉明码只能纠正一位错误.所以只能允许一块硬盘出问题.如果两块或以上硬盘出现问题，RAID 2的数据将被破坏. 其实是将原本连续的一个扇区数据，以位为单位分割存放在不连续的多块物理盘上.也就是条带深度为1. RAID 2不能实现并行IO，因为每次IO都要联动所有的磁盘，只能做到一个IO内部的并行. 基于其特点，能将顺序读写提升N倍，随机读写不能提升. RAID 3 采用异或的性质来求校验值.对于RAID 3 连续读写性能几乎是单盘的N倍.随机读写并没有提升，几乎和单盘一样. RAID 3 执行一次IO必须牵动占用所有盘，其他IO就必须等待，因此根本不能并发IO. 一般来说，RAID 3的条带长度=文件系统的块大小，避免条带不对齐的现象. 与RAID 2相同，只对大的连续读写有提升，小的随机读写没有优化. RAID 4 由于实际的读写常常是小的随机读写，前四种做法会有明显的缺陷，因此出现了RAID 4. RAID 4通过增大条带深度，大大增大了IO读写的并发性. RAID 5 由于RAID 4写请求需要共享校验盘，因此写请求不能实现并发.因此RAID 5将校验数据分散在各个磁盘上.使并发概率最大化. 新校验码=老数据XOR新数据XOR老校验码. 如果之前校验码出错，只能用新数据重新计算校验码，否则新校验码仍为错误. RAID 5磁盘数越多，可并发的几率越大. RAID 6 通过增加一个校验盘提高安全性，可以同时坏两块盘. 注意 如果随机小块IO多，则适当加大条带深度；如果连续大块IO多，则适当减少条带深度. 操作系统中RAID实现为了保证性能,同一磁盘组只能用同类型的磁盘,混合使用多类型磁盘组成虚拟磁盘非特殊要求不会有这样的设计.这种RAID称为软件RAID,存在如下缺点：①占用内存空间；②占用CPU资源（如利用异或求检验值等）；③软件RAID程序无法将安装有操作系统的那个磁盘分区做成RAID模式.RAID程序运行在操作系统之上,在启动操作系统之前无法实现RAID功能,因此操作系统损坏,RAID程序也无法运行,数据丢失. RAID卡其实是一种硬件实现RAID. 0通道RAID卡 自身没有SCSI通道,利用主板上已经集成或者已经插在PCI上的SCSI卡,来控制他们的通道. 无驱动RAID卡使用SATA接口连接计算机. RAID On Chip(ROC)技术利用SCSI卡上的CPU处理芯片,通过在SCSI卡的ROM中加入RAID代码而实现. RAID卡上内存用于存放CPU执行代码以及作为数据缓存.#虚拟磁盘 操作系统如何看待逻辑盘 目前各种RAID卡都可以划分逻辑盘，逻辑盘大小任意设置.每个逻辑盘对于OS来说都是一块单独的物理盘.而分区OS在一块物理磁盘上做的再次划分. 卷管理由于虚拟磁盘存在不灵活性,扩展上存在缺陷,因此出现了卷管理(Volume Manager,VM).很多操作系统上都有逻辑卷管理（LVM）.其主要功能是将OS识别到的物理磁盘（RAID卡虚拟化的逻辑盘）进行在组合. 相关概念 PV ： OS识别到的物理磁盘，叫物理卷（physical volume） VG ： 多个PV被逻辑的放到一个卷组(volume group)中 PP：即物理区块（physical partition）.是在逻辑上再将一个VG分割成连续的小块.逻辑上连续的PP物理上不一定连续. LP ： 逻辑区块.为实现某种功能,由多个PP组成的一个集合. LV ：由多个LP组成的逻辑卷. 总结起来就是将多个PV组合成一个存储集合VG,并在逻辑上将VG划分成若干PP.然后再在逻辑上组成若干LV.其中LV的基本单元是LP.而LP的基本单元是PP. 高级卷管理和低级卷管理 分区管理可以看做一种最简单的卷管理方式，它比LVM等要低级，比如windows自带的磁盘管理器.这些卷信息都存放在LBA1扇区上,这个扇区叫做主引导记录MBR,MBR还保存了BIOS跳转时所需要的第一句指令代码. 高级卷管理在划分逻辑卷之后,一定要记录逻辑卷是怎么划分的.LVM使用VGDA（volume group descriptior area）存放卷信息. 文件系统在一个没有文件系统的计算机上,如果一个程序要向磁盘上存储一些自己的数据,那么这个程序只能自己调用磁盘控制器驱动,或者调用VM提供的接口,对磁盘写数据.引入文件系统后,各个程序之间都通过文件系统接口访问磁盘,所有被写入的数据都称为一个文件,有名字,是一个实体.文件系统的IO包括同步IO、异步IO、阻塞IO/非阻塞IO和Direct IO.","tags":[{"name":"存储","slug":"存储","permalink":"http://yoursite.com/tags/存储/"},{"name":"RAID","slug":"RAID","permalink":"http://yoursite.com/tags/RAID/"},{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"排队论在ad hoc无线网中的应用","date":"2017-04-03T11:19:36.349Z","path":"2017/04/03/排队论在ad hoc无线网中的应用/","text":"Applications in Analysis of Ad Hoc Networks using Queuing Theory Yu Zhang Abstract Queuing problems are common scenarios in our daily life. From industrial manufacture to daily queuing, we can never leave this topic. Ad Hoc wireless networks are new kinds of networks. It has the advantages of high flexibility and extensibility, which are applied to our daily life gradually. The paper lists the applications in performance analysis of Ad Hoc networks via using queuing theory, and discusses their pros and cons as well as their development directions. At the end of the article, we reproduce some of the experiments via using MATLAB simulators and give a detailed discussion on the results. IntroductionQueuing Theory is a model discusses a dynamic service system’s running processes. In this system, the arrival of the customers is an exact stochastic process. When they arrive at the system, they will queue until it’s time for their service. After accepting service, customers are always supposed to leave. For instance, the M/M/1/∞ model (shown in Fig.1) is a classical model used commonly. In this model, we assume the arrival of the customers is an i.i.d. Poisson process and the time interval of only server is an exponential distribution. More importantly, there is an infinite queue length. Many complex models are its variations. Fig.1 A classical M/M/1 queuing model. In this model, we assume the arrival of the customers is an i.i.d. Poisson process and the time interval of only server is an exponential distribution. Ad hoc are networks without any base stations, i.e. infrastructure-less. Similar to the ZigBee protocol, they are self-organizing and adaptive networks, who allow spontaneous formation and deformation of networks topology. If node A can connect directly with node B, then they will save the other’s information at their own routing table, respectively. Another scenario is that A can only connect with B via intermedia C (shown in Fig. 2), then all of their routing tables will be updated to ensure that A can sense the existing of B. There are two topologies of ad hoc networks. One is heterogeneous, which means all the nodes have different capabilities. The other is homogeneous, i.e. all nodes have identical capabilities and responsibilities. Fig.2 Ad hoc network rules. If A can only connect with B via intermedia C, then all of their routing tables will be updated to ensure that A can sense the existing of B. There are great number of researches on ad hoc networks, and we can divide them into two kinds. On is to improve the performance via optimizing the protocol, e.g. MACA [1] and MACAW [2]. The former one uses the RTS/CTS mechanism to avoid the hidden terminal problem. And the latter one is an optimization of the first one who can solve the problem of exposed terminal. The other researches are on the problem of which protocol is the best, i.e. how to evaluate the specific system. And we will discuss this topic latter. The rest of the article is organized as follows. The second part of the article (section two) introduces applications in performance analysis of Ad Hoc networks via using queuing theory. The third part of the article (section three) we reproduce some of the experiments via using MATLAB simulators and give a detailed discussion on the results. Finally (section four) is the conclusions. Performance Analysis of Mobile Ad Hoc Networks using Queuing TheoryPerformance studies of ad hoc networks usually focus on either analytical modelling or simulations. We mainly discuss the evaluations via using Queuing theory. There are various publications on this topic. For instance, Jaehyuk Choi [3] analyzes the blocking probability and the queuing delay in the closed loop queue networks with finite queue length by using simulators. Daniele Miorandi [4] analyzes various performance indicators by of the wireless networks with HTTP traffic load by utilizing queuing models. Mustafa Ozdemir [5] analyzes how to design an efficient ad hoc network by using M/MMGI/1/K model. Saikat Ray [6] evaluates the mean delay and collision rate in ad hoc networks with hidden stations by using queuing simulators.We mainly discuss the Nabhendra Bisnik’s research on evaluating the ad hoc networks by establishing a G/G/1 network model, which seems to be more practical. The basic topology of the model [7] is shown in Fig. 3. The main idea of this paper is using diffusion approximation [8] to solve the G/G/1 model. The variables mentioned in this paper are shown as follow. The visit ratio of node i, denoted by ei, is given by e_i= p_0i (n)+ ∑p_ji (n)×e_j (1) The resulting arrival rate is termed the effective arrival rate at a station. The effective arrival rate at a node i, denoted by ‚i is given by λi= λ(e )× e_i (2) The utilization factor of station i, denoted by ρi, is given by ρ_i= λ_i ⁄ μ_i (3) Then by using the diffusion approximation, the paper get the closed form expressions of the mean delay (Formula 4) and the maximum throughput (Formula 5) of the model. D(n) = ρ_i⁄((λ×(1-ρ)) ) (4) λ_max= p(n)⁄((1/ξ+L/W+4nA(n) L/W ) ) (5) Fig. 3. The G/G/1 model of ad hoc networks with stationary nodes. Figure (a) shows the global nodes where P¬ij(n) means the probability that a package will transfer from node i to node j. While Figure (b) shows a single node in (a), and p(n) means the probability that the destination of a package is this node. From the above formulas, we can get the knowledge of the interplay of delay (or maximum throughput) and the visit ratio, the utilization factor and so on. However there are also some drawbacks in this research. For example, the mobile nodes are always mobilizable rather than stationary. What’s more, the queue length is always infinite in the real world rather than finite. So there are other researches to optimize this work, e.g. Aznida Hayati Zakaria [9] analyze a practical protocol with finite queue length via using their queue models, more information can refer to the article. SimulationFor the sake of simplicity, we consider an ad hoc network with only two mobile nods (Fig.4), and more complex scenarios are similar. Fig. 4 The simplest ad hoc network model with only two mobile nodes. As we can see in the picture, a1 means the arrival rate of Node1 while d1 is the departure rate, and p1 is the possibility that the page will be delivered to Node2. Node2 is the same. We can get there are nine states in this model. We express these states in matrix S, whose element S(i,j) means there are i packages in Node1 and j packages in Node2. s= (0,0) (0,1) (0,2) (1,0) (1,1) (1,2) (2,0) (2,1) (2,2) Easily, we can get the state-transition diagram (Fig. 5). Fig.5 The state-transition diagram. It the basis of our theoretical analysis. From the above diagram, we can list the balanced equation, and get the stability probabilities of each state.By using MATLAB, we analysis the package missing rate as well as throughput of each node. In the simulation, we assume that a1=1, a2=10, d1=6, d2=4, p1=2, p2=3, all of which can be got beforehead in real word. Fig.6 and Fig.7 are the simulation results, which denote the relationship between arrival rate (AR) and package missing rate (PMR). Fig.6 The relationship between arrival rate (AR) of node1 and its own package missing rate (PMR). Fig.7 The relationship between arrival rate of node2 and package missing rate of node1. From the simulation result, we can get that a node’s PMR increases as its own AR increases (Fig.6), while the influence from other nodes’ AR is negligible (Fig. 7). We have also found that a node’s throughput increases until an upper limit as its own AR increases (Fig 8). Fig.8 The relationship between AR and throughput. ConclusionsWe first introduce the queuing theory briefly. Then we list the applications in performance analysis of Ad Hoc networks via using queuing theory, and discusses their pros and cons as well as their development directions. Finally we reproduce some of the experiments via using MATLAB simulators and give a detailed discussion on the results, i.e. a node’s PMR increases as its own AR increases, while the influence from other nodes’ AR is negligible. We have also found that a node’s throughput increases until an upper limit as its own AR increases. Reference[1] P. Karn. MACA: a new channel access methos for packet radio. In Proceedings of the 9th Comouter Networking Conference, pages 134–140, September 1990. [2] V. Bharghavan, A. Demers, S. Shenker, and L. Zhang. MACAW: A media access protocol for wireless LANs. In SIGCOMM, pages 212–225. ACM Press, 1994. [3] G. Zeng, H. Zhu, and I. Chlamtac. A novel queueing model for 802.11 wireless LANs. In Proceedings of WNCG Wireless Networking Symposium, 2003. [4] D. Miorandi, A. A. Kherani, and E. Altman. A queueing model for HTTP traffic over IEEE 802.11 WLANs. In Proceedings of 16th ITC Specialist Seminar, August 2004. [5] M. Ozdemir and A. B. McDonald. An M/MMGI/1/K queuing model for IEEE 802.11 ad hoc networks. In Proceedings of PE-WASUN’05, pages 107–111. ACM Press, 2004 . [6] S. Ray, D. Starobinski, and J. B. Carruthers. Performance of wireless networks with hidden nodes: A queuing-theoretic analysis. To appear in Journal of Computer Communications. [7] N. Bisnik and A Abouzeid. Queuing Network Models for Delay Analysis of Multihop Wireless Ad Hoc Networks. International Wireless Communications &amp; Mobile Computing Conference, 2006. [8]G. Bolch, S. Greiner, H. de Meer, and K. S. Trivedi. Queuing Networks and Markov Chains, chapter 10, pages 423–430. John Wiley and Sons, 1998. [9]A. H. Zakaria, Y. M. Saman, A. S. Noor, etc. Performance Analysis of Mobile Ad Hoc Networks using Queuing Theory. Proceedings of the First International Conference on Advanced Data and Information Engineering, 2013. Original works, banned reproduced! If use, please indicate the source! ! ! 原创作品，禁止转载！若是转载，请注明出处！","tags":[{"name":"排队论","slug":"排队论","permalink":"http://yoursite.com/tags/排队论/"},{"name":"ad hoc无线网","slug":"ad-hoc无线网","permalink":"http://yoursite.com/tags/ad-hoc无线网/"}]},{"title":"存储相关-4-虚拟化与系统IO路径优化","date":"2017-04-03T11:19:36.349Z","path":"2017/04/03/存储相关-4-虚拟化与系统IO路径优化/","text":"几个概念 HPC（High Performance Computing）高性能计算通过增加整个计算系统CPU总核心数，可以成倍缩短执行时间 HAC（High available Computing）高可用性集群通过备份，当一活动节点发生故障时，备份可用，不会影响整个系统的使用 LBC负载均衡计算 理解主机端IO路径架构应用程序层 1. NFS下的缓存机制 默认mount参数下的IO 默认条件下使用异步(async)方式，rsize=wsize=65535。内核不会透传程序的IO给NFS Server,对于写IO会延缓执行，积累一定的时间以便合并上层的IO。不管读还是写，async方式都会具有一定的效果，尤其是连续的IO地址。 Linux下使用NFS，对于写操作，不管offset是否为Page或者512B对其，都没有任何写惩罚存在，对于读操作，也只在随机读的情况下出现了读惩罚，其他任何情况下都没有惩罚. 可以使用dd命令测试，dd是一个使用同步调用+buffered IO模式的程序.dd if=/mnt/3 of=/dev/null bs=1500 count=100dd为同步调用，到了底层，内核将dd的写IO数据合并，并且以异步的方式高效的发送给NFS服务器. 指定同步（sync）参数需要了解，内核的异步过程，只对Buffered IO模式下的同步写、异步写、异步读有意义.对于读立即执行，不一定表示不可以进行Prefetch和Cache Hit操作，但是对于写立即执行，却绝对不可以将待写的数据缓存起来延迟处理。 指定rsize/wsize参数rsize/wsize，对于NFS的IO逻辑没有任何影响，收到影响的只是底层传输的数据包数量和大小任何情况下均不要降低rsize或者wsize,百害而无一利。 使用O_DIRECT参数由于Linux下的NFS有很明显的预读力度。只在特定的条件下（小的随机读）有读惩罚，写惩罚一点也没有，因此很少使用DIO选项，除非应用中已经做了非常完善的缓存策略（如许多数据库就是如此）. 多进程访问下的缓存一致性解决方法Linux下的NFS缓存一致性，从严格到不严格一次为使用DIO模式、使用noac选项来mount、降低actimeo阈值到尽量低的值、默认mount参数。GETATTE是多客户端访问环境下NFS实现缓存一致性的法宝。###文件系统层文件系统一个最大的任务就是负责在逻辑文件与底层卷或者磁盘之间做映射，并且维护和优化这些映射信息。文件系统还需要负责向上层提供文件IO访问API接口，比如打开、读、写、属性修改、裁剪、扩充、锁等文件操作。另外，还需要维护缓存，包括预读、Write Back/Write Through/Flush等操作；还需要维护数据一致性，比如Log、FSCK等机制；还需要维护文件权限、Quota等。可以把一个文件系统逻辑上分为以下三个部分。 上部（访问接口） 中部（缓存管理、文件管理） 下部（文件映射、一致性保护、底层存储卷适配） 写命中是指写入的数据对应的地址在缓存中恰好在之前的尚未被写盘的IO数据。 卷管理层 块设备卷管理在某种程度上是为了弥补底层存储系统的一些不足之处，比如LUN空间的动态管理等。卷管理最大的任务是做Block级的映射，对于IO处理，卷层只是做一个将映射翻译之后的IO向下转发的动作以及反向过程。即使上层的IO不是4KB对齐，底层的IO也应该是4KB对齐的。 读惩罚当某个读IO请求的IO Size不可被OS Page Size或者Disk Sector Size整除时，这个读请求就会产生读惩罚。但是如果边界未4K对齐，仍然可能产生读惩罚。写惩罚写惩罚的表现是既有额外的读操作，又有额外的写操作。比读惩罚浪费更多的资源。 字符设备 概述传统的字符设备是转指一类接受字符流的物理终端、键盘等。这种设备可以直接对设备进行底层的操作而不使用缓存，而且每次IO必须以一个字符为单位。卷抽象出来的字符设备只是抽象出来了字符设备所具有的特点。对字符设备进行IO操作必须遵循底层的最小单位对齐规则，比如对于卷字符设备来说，每个IO长度只能是扇区。底层发出的IO长度与应用层发出的IO长度一一对应。 裸设备字符设备又被称为裸设备。寓意在于可以直接对裸设备进行IO操作，只不过需要自行维护数据，如扇区映射以及预读缓存等。由于使用文件系统缓存以及内核缓存容易造成数据的不一致性且容易造成读写惩罚，对于IO性能要求高的程序，可以直接操作底层的物理设备。 Direct IO如果即不想使用FS的缓存以防造成读写惩罚，又想利用文件系统的其他功能，则可以使用DIO模式。这里要注意一个概念，操作系统内有很多缓存，而用户程序的第一处缓存并不是通常理解的FS缓存，而是SystemBuffer。因为每发起一个IO请求，操作系统会根据程序IO请求的空间在操作系统内存空间分配相同大小的内存用于充当SystemBuffer，然后再往下才是文件系统缓存。 设备驱动层 SCSI设备驱动链其流程图如下 可以使用iostat工具监控IO状况。还可以使用blktrace对块级IO进行监控。 ATA设备驱动链Linux使用一种LibATA库来负责将SCSI协议转换为ATA协议并发送给ATA控制器驱动程序。 注意块设备由于底层IO Scheduler可能造成IO乱序重排执行情况，在发生系统宕机情况时，底层数据的一致性就无法得到保证。由于文件系统建立在块设备上，所以FSCK是一种恢复数据一致性的手段，但FSCK只能保证文件系统元数据的一致性却保证不了数据实际内容的一致性，所以，关键应用程序都直接使用完全透传程序IO请求的字符设备进行IO操作。 IO路径中Queue Depth和Queue LengthQueue Depth指的是Queue的最大长度，而Queue Length指的是Queue的当前长度。Queue Length在一定程度上反应了当前系统的忙闲程度，监测到的Queue Length越长，就证明Queue积压越大，那么单个IO的延迟也就越高。 IO Latency = （Queue Length + 1） IO Service Time = （Queue Length + 1） 其下层的IO Latency 如果IOPS尚未达到额定饱和值而Queue积压，那么说明瓶颈归于磁盘；如果IOPS饱和，说明瓶颈归于存储控制器的处理能力；如果带宽饱和，那么瓶颈归于链路本身。 time [-p] command [arguments…]time命令可以统计命令执行的时间 Queue Length 和 IOPS的关系IOPS = Queue Length / Average Response Time(ART) IO Size和IO延迟的关系IO Size越大，从盘片读写以及传输每个IO所用的时间就越长。所以，Write Merge操作其实增加了每个IO的延迟，但是它提高了效率，提高了系统的吞吐量。一些网络技术，如Infineband，其传输单元小，对于一些小的IO操作能够实现较高的响应速度，适合高实时性的传输，但是其整体的吞吐率不一定比其他传输技术高。 面向SSD的Queue优化需要更大的Queue Depth。","tags":[{"name":"存储","slug":"存储","permalink":"http://yoursite.com/tags/存储/"},{"name":"虚拟化","slug":"虚拟化","permalink":"http://yoursite.com/tags/虚拟化/"},{"name":"IO路径优化","slug":"IO路径优化","permalink":"http://yoursite.com/tags/IO路径优化/"}]},{"title":"存储相关-1-总线与存储器","date":"2017-04-03T11:19:36.349Z","path":"2017/04/03/存储相关-1-总线与存储器/","text":"1 IO总线分类 仲裁总线（控制总线） 地址总线 数据总线 PCI总线 PCI总线是目前普遍使用的一种连接南桥与外设的总线技术. PCI总线式数据与地址总线分时复用的. PCI总线所有时序的产生与控制都由Master发起，同一时刻只能供一对设备完成传输. PCI总线共享：硬件上使用三极管的物理特性实现，软件上通过中断链的方法实现. IO总线的结构 CPU与内存之间存在一个北桥芯片，这个芯片连接了CPU、内存与IO总线.CPU与北桥连接的叫系统总线（或者前端总线）.内存与北桥连接的叫内存总线.北桥与IO总线之间会有一个南桥芯片，协调北桥与IO总线之间的速度差.南桥负责连接控制众多的外设. 磁盘控制的指令集目前有ATA和SCSI指令集（或叫协议），SCSI比ATA指令集高效，所以广泛用于服务器和磁盘阵列环境. 2 磁盘原理与技术硬盘大致由盘片、读写头、马达、底座、电路板等几大项组成.盘片基板要求表面光滑平整，不可有任何瑕疵.磁粉需要不含杂质，并均匀地溅渡在磁盘上.磁头利用空气动力学使磁头悬浮于盘面之上.为了让磁头精确定位到每个磁道必须用步进电机，利用精确的齿轮组或者音圈，每次旋转可以仅仅使磁头进行微米级的位移. 盘上的数据组织 逻辑上分为磁道、柱面、扇区. 磁道从外圈向内圈从0开始编号，每一盘面有300~1024个磁道.磁道上每段圆弧叫做一个扇区.扇区从1开始编号，每个扇区中的数据作为一个单位同时读出或者写入，是读写的最小单位. 每个盘面会有一个磁头.只有同一柱面内从0磁头开始进行操作，向下所有柱面数据都读完时，磁头才会到下一个柱面，因此写数据都是先写满一个柱面，然后再写下一个柱面. 柱面（Cylinder）、磁头（Header）和扇区（Sector）三者简称CHS，所以扇区地址又称为CHS地址. 扇区的排列不是顺序的，而是根据交叉因子去调节的. SCSI接口完成了访问磁盘过程的虚拟化和抽象，极大的简化了访问磁盘的过程，它屏蔽了磁盘内部结构和逻辑. 磁盘相关高层技术 排队技术 无序传输技术 几种可控磁头扫描方式 FCFS(First Come First Serve) SSTF(Shortest Seek Time First) 控制器优先让磁头调到离当前磁头位置最近的IO磁道读写.存在不公平性，导致IO饿死. SCAN（回旋扫描模式） C-SCAN（单向扫描模式） LOOK(智能监控扫描模式) 与SCAN模式的区别在于，磁头不必到达终点之后才折返，而是完成最两端的IO即可折返. 在高负载的条件下，SCAN或者C-SCAN、C-CLOCK模式更为适合. 磁盘缓存 用来接收指令和数据，还用来进行预取.磁盘缓存表现为一块电路板上的RAM芯片，目前有2MB、8MB、16MB、32MB、64MB等容量规格. SCSI指令集中有两个参数可以控制对磁盘缓存的使用.DPO（Disable Page Out）和FUA（Force Unit Access）,当这两个参数都被设置为1时，相当于完全不使用磁盘缓存，但是指令和数据依然会先到达缓存中. 影响磁盘性能的因素 磁盘每个时刻只允许一个磁头来读写数据，因此多个磁头不可能提高磁盘的吞吐量和IO性能. 影响硬盘性能的因素包括：转速、寻道时间、单碟容量（越高，相同开销下读出数据越多）、接口速度（影响最小）. 硬盘接口技术 分类 用于ATA指令系统的IDE接口 用于ATA指令系统的SATA接口 用于SCSI指令系统的并行SCSI接口 用于SCSI指令系统的串行SCSI(SAS)接口. 用于SCSI指令系统的IBM专用串行SCSI接口(SSA). 用于SCSI指令系统的并且承载于FabreChannel协议的串行FC接口（FCP）. IDE硬盘接口技术 Integrate Drive Electronics 电子集成驱动器.即把控制电路和盘片、磁头等放在一个容器中的硬盘驱动器. 也叫PATA接口. ATA英文拼写为Advanced Technology Attachment，即高级技术附加. ATA-3引入了S.M.A.R.T(self-monitoring analysis and reporting technology，自监测、分析和报告技术). ATA-4和ATA-5分别叫ATA33和ATA66，意思为传输速度33.3MB/s和66.6MB/s，同时引入了CRC校验. ATA-7是ATA的最后一个版本,支持133MB/s的IDE硬盘，迈拓是唯一一家推行该协议的厂家.大部分都使用Serial ATA接口标准. IDE数据传输模式 PIO模式（Programming Input/Output Model）: 一种通过CPU执行I/O端口指令来进行数据读写的数据交换模式，是最早的硬盘数据传输模式.这种模式有较高的CPU占有率. DMA模式（Direct Memory Access）: 是一种不经过CPU而直接从内存存取数据的数据交换模式. Ultra DMA模式 ： 高级直接内存访问 SATA硬盘接口 SATA 2.0规范中添加的新特性包括：3Gb/s的传输速率；支持NCQ技术（Native Command Queuing ，自身命令队列）；端口选择器（Port Selector）；端口复用器（Port Multiplier）可以在一个控制器上扩展多个SATA设备 ；服务器特性；接口和连线的强化. SCSI硬盘接口对于ATA协议，对应的就是IDE接口；对于SCSI协议，对应的就是SCSI接口.SCSI全程Small Computer System Interface，即小型计算机系统接口.是一种具备与多种类型外设进行通行的能力，如硬盘，CD-ROM，磁带机和扫描机等. SCSI采用ASPI（高级SCSI编程接口）标准软件接口使驱动器和计算机内部安装的SCSI适配器进行通讯.缺点是价格过于昂贵. SCSI寻址机制和几个阶段 空闲阶段 仲裁阶段SCSI总线寻址方式，控制器-通道-SCSI ID -LUN ID来寻址.LUN（Logical Unit Number）对传统的SCSI总线来说意义不大，因为传统SCSI设备本身已经不可物理上再分了.因此设备的LUN ID为0.代表物理设备本身.对于带RAID功能的SCSI接口磁盘阵列设备来说，由于会产生的虚拟磁盘，所以只靠SCSI ID是不够的，这时候就要用LUN来扩充可寻址的范围. 选择阶段 磁盘控制器、驱动器 硬盘的接口包括接入到磁盘控制器上的物理接口以及定义的一套指令系统，即逻辑接口. 内部传输速率和外部传输速率 内部传输速率指刺头读写磁盘时的最高速率.这个速率不包括寻道以及等待扇区旋转到磁头下所用时间.通常每秒10000转的SCSI硬盘内部传输速率大概1000MB/s. 从外部接口传送给磁盘控制器时的传送速率就是硬盘的外部传输速率，10000转的SCSI硬盘实际外部传输速率只有80MB/s左右. 并行传输和串行传输 并行传输应用在长距离的连接上就无优点可言了.同时传输频率不能过高，因为电路高速震荡的时候，数据线之间会产生很大的干扰，所以并行传输的传输效率高但是速度慢. USB接口、IEEE1394接口以及COM接口都是串行传输的计算机外部接口. IO延迟、IOPS和传输带宽Throughput IO延迟是指控制器将IO指令发出后，知道IO完成的过程中所耗费的时间.业界又不成文的规定，IO延迟在20ms以内，对应用程序都是可以接受的.推算出IOPS=50. 控制器想存储设备发起指令不是一条一条顺序发送，而是一批一批的.也就是说，只要存储设备的肚量和消化能力足够，在IO比较少的时候，处理一条指令和多条指令的耗时几乎一样.控制器所发出批量指令的最大条数，有控制器上的Queue Depth决定. IOPS=（Queue Depth）/（IO Latency）对SCSI协议来说，完成一次连续LBA地址扇区的读写就算是一次IO，从底层看，每次想磁盘发送一个SCSI帧就是一次IO. 传输带宽 ： 具有高带宽规格的磁盘在传输大块连续数据时具有优势，而具有高IOPS的硬盘在传输小块不连续的数据时具有优势. 3 固态存储介质 结构对于一个16GB的FLASH，3214*8=34512个Cell逻辑上形成一个Page，每个Page中可以存放4KB的内容和218B的ECC校验数据，Page也是Flash芯片IO的最小单位.没128个Page组成一个Block，每2048个Block组成一个区域（Plane）.一整片Flash芯片由两个区域组成，一个区域存奇数序号的Blocks，一个存偶数序号的Blocks. 读写过程 对于小块随机IO，Flash会随着容量的增加而变得越来越低效.SSD的IO最小单位为1个Page. Flash写入之前必须Erase.Cell带负电荷电表示0，不带电表示1.Erase即是释放电子的过程.若写1，则不作任何操作；若写0，则该Cell充入电子，写0的过程叫programme. SSD的诟病与补救 拆东墙补西墙。为实现Wear Leveling，通过FTL映射实现IO的重定向. 定期清理体内垃圾 : Wiper TRIM支持 Delay Write减少对SSD的写 预留一部分空间不写 存储器的读写延迟总结","tags":[{"name":"存储","slug":"存储","permalink":"http://yoursite.com/tags/存储/"},{"name":"总线","slug":"总线","permalink":"http://yoursite.com/tags/总线/"}]},{"title":"在github pages上建站","date":"2017-04-03T11:19:36.349Z","path":"2017/04/03/在github pages上建站/","text":"好记性不如烂笔头，计算机科学日新月异，养成写博客的习惯对于程序猿来说尤为关键，于是便搭了自己的博客！ 建站过程中参见的博客有使用Hexo建站十分便利，下面是建站过程中主要参见的博客 手把手教你使用Hexo + Github Pages搭建个人独立博客 在Windows平台上安装Node.js及NPM模块管理 GithubPages+Hexo博客主题Yilia yilia作者的使用建议 非常有用的Markdown 编辑器和工具 Markdown 语法说明 (简体中文版) 献给写作者的 Markdown 新手指南 添加访客数量统计 添加站内搜索 添加返回顶部功能 其中值得注意的是，下载完git工具后，需要输入下面两条命令来设置github账号和邮箱！！！！然后会有弹框要求输入用户名和密码，输入正确即可正常部署了！！！否则会出下图的错误！ 12git config --global user.email &quot;you@example.com&quot;git config --global user.name &quot;Your Name&quot;","tags":[{"name":"github pages","slug":"github-pages","permalink":"http://yoursite.com/tags/github-pages/"},{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]},{"title":"存储相关-3-磁盘阵列以及存储系统(DAS、SAN和NAS)","date":"2017-04-03T11:19:36.349Z","path":"2017/04/03/存储相关-3-磁盘阵列以及存储系统(DAS、SAN和NAS)/","text":"磁盘阵列多个磁盘通过RAID卡组合起来,组成JBOD（just a bound of Disks,一串磁盘）.JBOD称为磁盘柜,凡是自带RAID控制器的盘柜就叫做磁盘阵列或者盘阵. 双控制器常用两个控制器来保证磁盘阵列的安全性 Active-Standby热备份 一个作为备份，只有当主控制器故障时副控制器才工作 Dual-Active双控制器同时工作两个同时工作，当其中一个故障时，另一个仍能正常接管整个阵列的管理. Split Brain脑分裂其中一个控制器检测不到另一个控制器的存在,则向电源控制器发送信号，重启对方并进入Standby状态. DAS、SAN和NASDAS (Direct Attached Storage)直接附加网络直连式存储与服务器主机之间的连接通道通常采用SCSI连接，随着服务器CPU的处理能力越来越强，存储硬盘空间越来越大，阵列的硬盘数量越来越多，SCSI通道将会成为IO瓶颈；服务器主机SCSI ID资源有限，能够建立的SCSI通道连接有限。由于存储设备通过电缆直接与计算机相连，系统存取访问I/O请求直接在计算机和存储设备之间进行，故会受如下因素制约 硬盘 内存缓存 虚拟内存 存储控制器 RAID级别以及读写模式 总线长度 DAS面临的挑战 存储与主机必须直连 数据可用性 单节点故障 数据资源的共享 可扩展性有限 连接的端口和主机有限 有限的可寻址范围（即容量有上限） 距离限制 需要停机维护 NAS(Network Attached Storage)附网存储由于DAS存在上述的一系列限制,网络存储渐渐浮出水面,并得到了广泛应用. 网络存储的本质是通过网络建立用户与存储设备之间的连接，通过网络传输数据. 技术上通过软件提供高性能的文件服务. NAS本质是一个专用的文件服务器，NAS不一定是盘阵，一台主机只要它有自己的磁盘和文件系统，并向外提供访问文件系统的接口（如NFS、CIFS等），就可以做成NAS. NAS其实就是处于以太网上的一台利用NFS、CIFS等网络文件系统的文件共享服务器. 一种瘦服务器方式的存储设备 NAS传输协议 CIFS(Common Internet File System) 微软定义的一套规范 基于Windows NT的公共互联网文件系统 使用TCP协议 在服务器端验证用户身份，比NFS安全 NFS(Network File System) Unix/Linux使用的协议 底层使用TCP或者UDP协议 开销远远小于CIFS 在用户端安全登录 SAN（Storage Area Net）存储局域网 SAN采用网络互连的存储区域网. FC-SAN得到了广泛应用，使用FC协议网络通讯. SAN只支持SCSI协议，SCSI语言及数据可以用FC协议传递。 NAS和SAN对比 速度对比除非NAS使用快于内存的网络方式与主机通讯，否则其速度永远无法超过SAN架构。但是如果后端磁盘有瓶颈，那么NAS用网络代替内存的方法产生的性能降低就可以忽略。 成本对比NAS比SAN成本低很多 可扩展性NAS可扩展性强于SAN，只要有IP的地方，NAS 就可以提供服务，且容易部署和配置。NAS设备一般都可以提供多种协议访问数据，而SAN只能使用SCSI协议访问。 数据共享NAS可以被多个客户端访问，SAN除非安装了专门的集群管理系统或集群文件系统模块，否则不能共享某个LUN. SAN和NAS的选择CPU不密集但是大块连续IO密集的应用选择SAN比较合适对于IO不密集的随机小块IO场景选择NAS，NAS的根本瓶颈是底层链路的速度，若为高速以太网,首选NAS. 备注目前普遍的架构是文件系统和磁盘控制器驱动程序都运行在应用服务器主机上。文件系统向卷发送的请求是通过内存来传递的，而主机向磁盘（LUN）发送的请求是通过FC网络来传递的。（SAN）","tags":[{"name":"存储","slug":"存储","permalink":"http://yoursite.com/tags/存储/"},{"name":"存储阵列","slug":"存储阵列","permalink":"http://yoursite.com/tags/存储阵列/"},{"name":"存储系统","slug":"存储系统","permalink":"http://yoursite.com/tags/存储系统/"}]}]